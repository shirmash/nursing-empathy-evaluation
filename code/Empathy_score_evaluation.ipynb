{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fdb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Empathy score evaluation (1–5 scale)\n",
    "# -------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ==== FILE & COLUMN NAMES (edit if yours differ) ====\n",
    "FILE_PATH = \"records_informations.xlsx\"\n",
    "SHEET = \"Sheet1\"\n",
    "LABEL_COL = \"Using compassionate and empathetic language\"\n",
    "PRED_COL  = \"gpt_empathy score\"\n",
    "\n",
    "# ==== LOAD DATA ====\n",
    "df = pd.read_excel(FILE_PATH, sheet_name=SHEET)\n",
    "\n",
    "# keep only rows with numeric label & prediction\n",
    "df = df[[LABEL_COL, PRED_COL]].copy()\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "\n",
    "y_true = df[LABEL_COL].astype(float).to_numpy()\n",
    "y_pred = df[PRED_COL].astype(float).to_numpy()\n",
    "\n",
    "# ==== ERRORS & METRICS ====\n",
    "abs_err = np.abs(y_true - y_pred)\n",
    "mae = abs_err.mean()\n",
    "std_err = abs_err.std(ddof=0)  # population std\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "# Random baseline (uniform between 1 and 5 inclusive)\n",
    "rng = np.random.default_rng(42)     # reproducible\n",
    "y_rand = rng.integers(1, 6, size=len(y_true))\n",
    "rmse_rand = mean_squared_error(y_true, y_rand, squared=False)\n",
    "\n",
    "# Optional constant baselines\n",
    "y_const_mean = np.full_like(y_true, fill_value=y_true.mean())\n",
    "rmse_const_mean = mean_squared_error(y_true, y_const_mean, squared=False)\n",
    "\n",
    "mode_val = pd.Series(y_true).mode().iloc[0]\n",
    "y_const_mode = np.full_like(y_true, fill_value=mode_val)\n",
    "rmse_const_mode = mean_squared_error(y_true, y_const_mode, squared=False)\n",
    "\n",
    "print(f\"Samples: {len(y_true)}\")\n",
    "print(f\"MAE:  {mae:.3f}\")\n",
    "print(f\"STD(error): {std_err:.3f}\")\n",
    "print(f\"RMSE (GPT): {rmse:.3f}\")\n",
    "print(f\"RMSE (Random 1–5): {rmse_rand:.3f}\")\n",
    "print(f\"RMSE (Const=mean={y_true.mean():.2f}): {rmse_const_mean:.3f}\")\n",
    "print(f\"RMSE (Const=mode={mode_val:.0f}): {rmse_const_mode:.3f}\")\n",
    "\n",
    "# ==== PLOTS ====\n",
    "\n",
    "# 1) Histogram of absolute errors\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(abs_err, bins=range(0,6), align=\"left\", rwidth=0.8, edgecolor=\"black\")\n",
    "plt.xticks(range(0,6))\n",
    "plt.xlabel(\"Absolute Error (scale 1–5)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Prediction Errors\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Bar with mean ± 1 std of error\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar([\"Error\"], [mae], yerr=[std_err], capsize=10, edgecolor=\"black\")\n",
    "plt.ylabel(\"Error (scale 1–5)\")\n",
    "plt.title(\"Mean Absolute Error with Standard Deviation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) RMSE comparison: GPT vs Random (and optional constants)\n",
    "labels = [\"GPT\", \"Random\", \"Const-Mean\", \"Const-Mode\"]\n",
    "vals = [rmse, rmse_rand, rmse_const_mean, rmse_const_mode]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "bars = plt.bar(labels, vals, edgecolor=\"black\")\n",
    "for i, v in enumerate(vals):\n",
    "    plt.text(i, v + 0.03, f\"{v:.2f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "plt.ylabel(\"RMSE (scale 1–5)\")\n",
    "plt.title(\"RMSE Comparison\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
